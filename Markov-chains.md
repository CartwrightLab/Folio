# Markov Chains and Mutation

## Introduction

A Markov chain is a stochastic model describing how a random variable changes through time. Markov chains are memoryless, and future states depend only on the current state of the chain and not on any past states. This is known as the Markov property. 

## Discrete-Time Markov Chains

A discrete-time Markov chain is a sequence of random variables generated by a stochastic process in which the value of the next variable depends only on the value of the current variable. For example, consider a simple Markovian weather model in which days are either dry or wet. If today is dry, then tomorrow has a 90% chance of being dry and a 10% chance of being wet. If today is wet, then tomorrow has a 30% chance of being wet and a 70% chance of being dry. Whatever happens tomorrow is conditionally independent of what happened yesterday. This can be represented by a graphical model with two states and four edges.

![](images/weather.svg)

This information can also be represented using a matrix describing the transition from today to tomorrow:
$P = \left[
\begin{matrix}
0.9 & 0.1\\
0.7 & 0.3\\
\end{matrix}
\right]$.

### Definition
A discrete-time Markov chain is a sequence of random variables $X_0, X_1, X_2, \ldots$ with the Markov property:

$$\Pr(X_{n+1} = x | X_0 = x_0, X_1 = x_1, \ldots , X_n = x_n) = \Pr(X_{n+1} = x | X_n = x_n)$$

Assuming time-homogeneity, the behavior of this chain can be encoded into a single transition matrix, $P$, such that $p_{ij} = \Pr(X_{n+1} = j | X_n = i)$.

Let $\pi^{(n)}$ be (row) vector describing the distribution of states of the chain at time $t=n$, i.e. $\pi^{(n)}_i = \Pr(X_{n} = i)$, where $(n)$ is an index and not a power. This vector can be calculated from  $\pi^{(n-1)}$ using matrix multiplication:

$$\pi^{(n)} = \pi^{(n-1)} \times P = \pi^{(n-2)} \times P \times P = \pi^{(0)} \times P^n$$

where $\pi^{(0)}$ represents the initial distribution of states at time $t = 0$.

### Mutation

Consider a haploid DNA locus for four states $X \in \{1, 2, 3, 4\}$. These states could represent different nucleotides or different alleles. The transmission of this locus from one generation to the next can be represented by a transition matrix

$$P = \begin{matrix}
 1 - (u_{12} + u_{13} + u_{14}) & u_{12} & u_{13} & u_{14}\\
u_{21} & 1 - (u_{21} + u_{23} + u_{24}) & u_{23} & u_{24}\\
u_{31} & u_{32} & 1 - (u_{31} + u_{32} + u_{34}) & u_{34}\\
u_{41} & u_{42} & u_{43} & 1 - (u_{41} + u_{42} + u_{43})\\
\end{matrix}$$

where the off diagonals represent mutation events and the diagonals represent no mutation.  If this locus is transmitted clonally (e.g. mitochondrial DNA), then $\Pr(X_n = j | X_0 = i) = P^{(n)}_{ij}$ where $P^{(n)} = P^n$.

#### Probability of No Mutations

$\Pr(X_n = i | X_0 = i)$ does not measure the probability that no mutation occurred, only that the state is the same after $n$ generations. To calculate $\Pr(X_n = j \text{ and zero mutations} | X_0 = i)$, we will first first split $P$ into two matrices, $P = Z + M$, such that $Z$ contains the diagonal elements of $P$ and $M$ contains the off-diagonals. From here, it is straightforward to calculate

$$\left[\;\Pr(X_n = j \text{ and zero mutations} | X_0 = i)\;\right] = Z^n$$

#### Probability of One Mutation

If one and only one mutation occurred across $n$ generations, then there are $n$ possible time points when the mutation occurred. The probability of one and only one mutation occurring across $n$ generations can be calculated by summing over all possible time points

$$\left[\;\Pr(X_n = j \text{ and one mutation} | X_0 = i)\;\right] =
\sum_{k=1}^n Z^{k-1} M^1 Z^{n-k} = n M^1 Z^{n-1}$$

The simplification is possible because $Z$ is a diagonal matrix.

#### Probability of K Mutations

Generally, the probability of $k$ mutations can be calculated in a manner reminiscent of a binomial distribution:

$$\left[\;\Pr(X_n = j \text{ and k mutations} | X_0 = i)\;\right] = {n \choose k} M^k Z^{n-k}$$

## Continuous-Time Markov Chains

A continuous-time Markov chain is similar to a discrete-time Markov chain, except that transitions between states are not restricted to occur at discrete time points. Here, if we know the state of the stochastic process at a specific time point, then what will happens in the future is independent of what happened in the past.

In the continuous-time analog of our weather model, being wet or dry is now a property of every specific point of time and not restricted to daily summary.

### Definition

Let $X_t$ be a random variable representing the state of a continuous-time Markov chain at time $t$. Therefore, following the Markov property, if $X_t$ is known and $h > 0$, then $X_{t+h}$ is independent of $X_s$ for all $s < t$. The conditional probability that $X_{t+h} = j$ given $X_t = i$ can be defined as $h \to 0$ as

$$\Pr(X_{t+h} = j | X_t = i) = \delta_{ij} + q_{ij} h + o(h)$$

where $\delta_{ij}$ is the Kronecker delta and $q_{ij}$ is non-negative if  $i \ne j$. Here $q_{ij}$ represents how quickly the transition from $i$ to $j$ happens.

Let $P(h)$ be the transition matrix representing the conditional transition between the starting and end points of a time span of length $h$. Consistent with the definition above, $P(h) \approx I + Qh$ as $h \to 0$, where $I$ is the identity matrix and $Q$ is the transition rate matrix. The elements of $Q$ are defined as above where $q_{ij}$ is non-negative if $i \ne j$, and $q_{ii}$ is chosen such that the every row sums to 0.

Now consider a time span of length $t$, subdivided into $n$ independent sections. Since the subdivisions are independent, the total transition matrix is the product of the transition matrices of the individual subdivisions:

$$P(t) \approx \left(I + \frac{Qt}{n} \right)^n$$

If we take the limit as $n \to \infty$, we get the formula for $P(t)$ using matrix exponentiation:

$$\left[\;\Pr(X_t = j | X_0 = i)\;\right] = P(t) = \lim_{n \to \infty} \left(I + \frac{Qt}{n} \right)^n = e^{Qt}$$

#### Probability of No Mutations

As above, let $Z$ hold the diagonal entries of $Q$ and $M$ hold the off-diagonals, such that $Q = Z + M$. Next let $P_0(t) = \left[p(t, i, j, 0)\right]$, where $p(t, i, j, 0) = \Pr(X_t = j \text{ and no mutations} | X_0 = i)$. Therefore,

$$P_0(t) = \lim_{n \to \infty} \left(I + \frac{Zt}{n} \right)^n = e^{Zt}$$

#### Probability of One Mutation

Define $P_1(t)$ similar to $P_0(t)$ as the joint one-mutation-transition matrix.

$$P_1(t) = \lim_{n \to \infty} n \frac{M t}{n} \left(I + \frac{Zt}{n} \right)^{n-1} = M t e^{Zt}$$

#### Probability of K Mutations

Generally, the probability of $k$ mutations can be calculated in a manner reminiscent of a Poisson distribution:

$$P_k(t) = \lim_{n \to \infty}
{n \choose k}
\left(\frac{Mt}{n}\right)^k
\left(I + \frac{Zt}{n} \right)^{n-k} = \frac{\left(M t\right)^k}{k!} e^{Zt}$$